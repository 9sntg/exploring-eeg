{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8caf7a0eb91644a3a9d08a51d175b2b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ab6e485609c40fc85c6706a280c59e6","IPY_MODEL_d3364ef511cf4729b1dbcc15abb18d7a","IPY_MODEL_7128abc0efde4d9e8b0bc9ac090eb042"],"layout":"IPY_MODEL_b634f548c9fe454db53cdb637f3b9246"}},"3ab6e485609c40fc85c6706a280c59e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ccef98dca3a451788ad94e6f2c22b39","placeholder":"​","style":"IPY_MODEL_b3f0106f77db46f4a18c1202d195f28d","value":"config.json: "}},"d3364ef511cf4729b1dbcc15abb18d7a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1fe8843cfac435398edb841ba44f732","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_70576ebf3b0a4eeca4bea3c18f9a6403","value":1}},"7128abc0efde4d9e8b0bc9ac090eb042":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8250056f1e524398a9c7d039f7b3a554","placeholder":"​","style":"IPY_MODEL_d4c3d62733d34c08887cae5b00106b92","value":" 4.19k/? [00:00&lt;00:00, 251kB/s]"}},"b634f548c9fe454db53cdb637f3b9246":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ccef98dca3a451788ad94e6f2c22b39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3f0106f77db46f4a18c1202d195f28d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1fe8843cfac435398edb841ba44f732":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"70576ebf3b0a4eeca4bea3c18f9a6403":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8250056f1e524398a9c7d039f7b3a554":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4c3d62733d34c08887cae5b00106b92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e99ac0d6b384e369ef28a9ea63d1709":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd4333372b5e44aa874c030dc81470d8","IPY_MODEL_73d18e7d93894a4b9fc55cffb9f5f44f","IPY_MODEL_b47580f566f6411da1e3fffbc9c3b8ca"],"layout":"IPY_MODEL_1e50c7ac459f4896a1834371a3141cb3"}},"fd4333372b5e44aa874c030dc81470d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9dbae765dbe84175a185c32d0948176c","placeholder":"​","style":"IPY_MODEL_287077f798b843d0aae5ce66e7f8782c","value":"pytorch_model.bin: 100%"}},"73d18e7d93894a4b9fc55cffb9f5f44f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1edda35d23041d8ad6bb15360504239","max":605247071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4845f84ec47a4af6a263fcab014c3efc","value":605247071}},"b47580f566f6411da1e3fffbc9c3b8ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_187a32655a044184a972d5d1dae8c76d","placeholder":"​","style":"IPY_MODEL_4d50bd67a2494f2c8eb6ff3fddf7939d","value":" 605M/605M [00:05&lt;00:00, 135MB/s]"}},"1e50c7ac459f4896a1834371a3141cb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dbae765dbe84175a185c32d0948176c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"287077f798b843d0aae5ce66e7f8782c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1edda35d23041d8ad6bb15360504239":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4845f84ec47a4af6a263fcab014c3efc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"187a32655a044184a972d5d1dae8c76d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d50bd67a2494f2c8eb6ff3fddf7939d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"455a5c4dc76f4d4790da977fc859107e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9424d43f590e4ee3ac8ed5ae250723ad","IPY_MODEL_b3ca2fab63414e3390f68f02c50c3669","IPY_MODEL_1d52d88726754dbf8fde2ac22d974d28"],"layout":"IPY_MODEL_878dbc5144c04a3fa66f9a99fb86b45b"}},"9424d43f590e4ee3ac8ed5ae250723ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bedd1e2af17e4d6aa2e8703709a13281","placeholder":"​","style":"IPY_MODEL_d5fef0192793434e923dda1e3cdecc90","value":"model.safetensors: 100%"}},"b3ca2fab63414e3390f68f02c50c3669":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_424a3cec34284a4cb0b8aa2cc07e08d1","max":605157884,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a37a72eee604f3eb819241efc1edd9b","value":605157884}},"1d52d88726754dbf8fde2ac22d974d28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcc2954d7daa40818fbe38f08119b7a6","placeholder":"​","style":"IPY_MODEL_23f45931ae814aa59000e26a43886324","value":" 605M/605M [00:14&lt;00:00, 53.7MB/s]"}},"878dbc5144c04a3fa66f9a99fb86b45b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bedd1e2af17e4d6aa2e8703709a13281":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5fef0192793434e923dda1e3cdecc90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"424a3cec34284a4cb0b8aa2cc07e08d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a37a72eee604f3eb819241efc1edd9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fcc2954d7daa40818fbe38f08119b7a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23f45931ae814aa59000e26a43886324":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# CLIP Fine-Tuning: Partial Freezing, and LoRA\n","\n","This script demonstrates:\n","\n","*   CLIP architecture (text encoder, vision encoder).\n","*   Freezing all parameters.\n","*   Unfreezing projection layer.\n","*   Unfreezing last N transformer layers.\n","*   Applying Parameter-Efficient Fine-Tuning (PEFT): LoRA."],"metadata":{"id":"QsjSV93diNp7"}},{"cell_type":"code","source":["# PFET: Parameter-Efficient Fine-Tuning\n","!pip install transformers peft -q"],"metadata":{"id":"w-NHf3TUgKlD","executionInfo":{"status":"ok","timestamp":1759598134640,"user_tz":240,"elapsed":17294,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import CLIPModel\n","from peft import LoraConfig, get_peft_model\n","import pandas as pd"],"metadata":{"id":"_Om-0Rk5gMpz","executionInfo":{"status":"ok","timestamp":1759598182850,"user_tz":240,"elapsed":43000,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Function to count trainable and frozen parameters\n","def count_parameters(model):\n","    trainable, frozen = 0, 0\n","    for name, param in model.named_parameters():\n","        if param.requires_grad:\n","            trainable += param.numel()\n","        else:\n","            frozen += param.numel()\n","    total = trainable + frozen\n","    print(f\"Trainable params: {trainable:,}\")\n","    print(f\"Frozen params:    {frozen:,}\")\n","    print(f\"Total params:     {total:,}\")\n","    print(f\"Trainable ratio:  {100*trainable/total:.2f}%\")"],"metadata":{"id":"LT7JCMDdgSeh","executionInfo":{"status":"ok","timestamp":1759598182861,"user_tz":240,"elapsed":2,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# 1. CLIP Architecture Overview"],"metadata":{"id":"lTlU2vE1jzwm"}},{"cell_type":"markdown","source":["### Load the model"],"metadata":{"id":"inm0gS_BrRO8"}},{"cell_type":"code","source":["model_name = \"openai/clip-vit-base-patch32\"\n","model = CLIPModel.from_pretrained(model_name)"],"metadata":{"id":"3PPMUrZ8gWgi","colab":{"base_uri":"https://localhost:8080/","height":237,"referenced_widgets":["8caf7a0eb91644a3a9d08a51d175b2b8","3ab6e485609c40fc85c6706a280c59e6","d3364ef511cf4729b1dbcc15abb18d7a","7128abc0efde4d9e8b0bc9ac090eb042","b634f548c9fe454db53cdb637f3b9246","0ccef98dca3a451788ad94e6f2c22b39","b3f0106f77db46f4a18c1202d195f28d","c1fe8843cfac435398edb841ba44f732","70576ebf3b0a4eeca4bea3c18f9a6403","8250056f1e524398a9c7d039f7b3a554","d4c3d62733d34c08887cae5b00106b92","1e99ac0d6b384e369ef28a9ea63d1709","fd4333372b5e44aa874c030dc81470d8","73d18e7d93894a4b9fc55cffb9f5f44f","b47580f566f6411da1e3fffbc9c3b8ca","1e50c7ac459f4896a1834371a3141cb3","9dbae765dbe84175a185c32d0948176c","287077f798b843d0aae5ce66e7f8782c","a1edda35d23041d8ad6bb15360504239","4845f84ec47a4af6a263fcab014c3efc","187a32655a044184a972d5d1dae8c76d","4d50bd67a2494f2c8eb6ff3fddf7939d","455a5c4dc76f4d4790da977fc859107e","9424d43f590e4ee3ac8ed5ae250723ad","b3ca2fab63414e3390f68f02c50c3669","1d52d88726754dbf8fde2ac22d974d28","878dbc5144c04a3fa66f9a99fb86b45b","bedd1e2af17e4d6aa2e8703709a13281","d5fef0192793434e923dda1e3cdecc90","424a3cec34284a4cb0b8aa2cc07e08d1","5a37a72eee604f3eb819241efc1edd9b","fcc2954d7daa40818fbe38f08119b7a6","23f45931ae814aa59000e26a43886324"]},"outputId":"e619a7c6-fa43-4589-86e5-4d72abf1a4d1","executionInfo":{"status":"ok","timestamp":1759598196954,"user_tz":240,"elapsed":6684,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8caf7a0eb91644a3a9d08a51d175b2b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e99ac0d6b384e369ef28a9ea63d1709"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"455a5c4dc76f4d4790da977fc859107e"}},"metadata":{}}]},{"cell_type":"markdown","source":["### High-Level Modules"],"metadata":{"id":"8x3b36s7kPAf"}},{"cell_type":"code","source":["for name, module in model.named_children():\n","    print(f\"{name}: {module.__class__.__name__}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"InQlNOnvkHfU","outputId":"acf02892-866f-459d-80c2-7dfa60ae64f9","executionInfo":{"status":"ok","timestamp":1759598197353,"user_tz":240,"elapsed":10,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["text_model: CLIPTextTransformer\n","vision_model: CLIPVisionTransformer\n","visual_projection: Linear\n","text_projection: Linear\n"]}]},{"cell_type":"markdown","source":["### Text and Image Models"],"metadata":{"id":"-Waxf4Uekj7I"}},{"cell_type":"code","source":["print('text Transformer:')\n","print(model.text_model)\n","print('\\n')\n","print('Image Transformer:')\n","print(model.vision_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7wGOXWskk1z","outputId":"b0531877-684c-4b59-e84b-0e62990f6ca9","executionInfo":{"status":"ok","timestamp":1759598206404,"user_tz":240,"elapsed":8,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["text Transformer:\n","CLIPTextTransformer(\n","  (embeddings): CLIPTextEmbeddings(\n","    (token_embedding): Embedding(49408, 512)\n","    (position_embedding): Embedding(77, 512)\n","  )\n","  (encoder): CLIPEncoder(\n","    (layers): ModuleList(\n","      (0-11): 12 x CLIPEncoderLayer(\n","        (self_attn): CLIPAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): CLIPMLP(\n","          (activation_fn): QuickGELUActivation()\n","          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",")\n","\n","\n","Image Transformer:\n","CLIPVisionTransformer(\n","  (embeddings): CLIPVisionEmbeddings(\n","    (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n","    (position_embedding): Embedding(50, 768)\n","  )\n","  (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  (encoder): CLIPEncoder(\n","    (layers): ModuleList(\n","      (0-11): 12 x CLIPEncoderLayer(\n","        (self_attn): CLIPAttention(\n","          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): CLIPMLP(\n","          (activation_fn): QuickGELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",")\n"]}]},{"cell_type":"markdown","source":["### Projection Layers\n","\n","To allow both outputs of text and image transformers to have same dimensions"],"metadata":{"id":"pVtL9Wrglce0"}},{"cell_type":"code","source":["print(model.text_projection)    # text → joint space\n","print(model.visual_projection)  # vision → joint space"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qddUmXBMkg-u","outputId":"dfac263a-6e38-439f-d862-e59c6d4f5518","executionInfo":{"status":"ok","timestamp":1759598247748,"user_tz":240,"elapsed":17,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear(in_features=512, out_features=512, bias=False)\n","Linear(in_features=768, out_features=512, bias=False)\n"]}]},{"cell_type":"markdown","source":["# 2. Freezing / unfreezing CLIP"],"metadata":{"id":"Ofts7GAhv959"}},{"cell_type":"markdown","source":["### Freeze all parameters"],"metadata":{"id":"wTafLn2Zm5-s"}},{"cell_type":"code","source":["# freeze all\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","print(\"All parameters frozen\")\n","count_parameters(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHSQSIVMghyH","outputId":"27151b7c-9e64-45f2-f7ab-1b6e82282403","executionInfo":{"status":"ok","timestamp":1759598272560,"user_tz":240,"elapsed":50,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["All parameters frozen\n","Trainable params: 0\n","Frozen params:    151,277,313\n","Total params:     151,277,313\n","Trainable ratio:  0.00%\n"]}]},{"cell_type":"markdown","source":["### Unfreeze text projection head only"],"metadata":{"id":"Dk01R9R5nJZa"}},{"cell_type":"code","source":["# load model\n","model_proj = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","# freeze all\n","for param in model_proj.parameters():\n","    param.requires_grad = False\n","\n","# unfreeze the text projection head\n","for param in model_proj.text_projection.parameters():\n","    param.requires_grad = True\n","\n","print(\"Text projection layer unfrozen\")\n","count_parameters(model_proj)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTsPmxksgj-H","outputId":"38c4b8b6-6faa-4d7e-f080-83670b47190b","executionInfo":{"status":"ok","timestamp":1759598287105,"user_tz":240,"elapsed":541,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Text projection layer unfrozen\n","Trainable params: 262,144\n","Frozen params:    151,015,169\n","Total params:     151,277,313\n","Trainable ratio:  0.17%\n"]}]},{"cell_type":"markdown","source":["#### Check trainable parameters"],"metadata":{"id":"-EY5gm1DPmk4"}},{"cell_type":"code","source":["for name, p in model_proj.named_parameters():\n","    if p.requires_grad:\n","        print(\"Trainable:\", name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"925869c9-4eff-418f-a89e-d18628d2b8f3","id":"iT1SD2ElPmk6","executionInfo":{"status":"ok","timestamp":1759598313186,"user_tz":240,"elapsed":15,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable: text_projection.weight\n"]}]},{"cell_type":"markdown","source":["### Unfreeze last *N* transformer layers"],"metadata":{"id":"zQb1_PU8nZGE"}},{"cell_type":"code","source":["# load model\n","model_last2 = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","# freeze all\n","for param in model_last2.parameters():\n","    param.requires_grad = False\n","\n","# unfreeze last N layers in the text encoder\n","N = 2\n","layers = model_last2.text_model.encoder.layers\n","\n","for layer in layers[-N:]:\n","    for param in layer.parameters():\n","        param.requires_grad = True\n","\n","print(f\"Last {N} transformer layer(s) unfrozen\")\n","count_parameters(model_last2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WyXh_7_LgoMl","outputId":"e187c351-b520-4032-94da-f4c51eede872","executionInfo":{"status":"ok","timestamp":1759598322756,"user_tz":240,"elapsed":651,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Last 2 transformer layer(s) unfrozen\n","Trainable params: 6,304,768\n","Frozen params:    144,972,545\n","Total params:     151,277,313\n","Trainable ratio:  4.17%\n"]}]},{"cell_type":"markdown","source":["#### Check trainable parameters"],"metadata":{"id":"_9ArBgpbPcww"}},{"cell_type":"code","source":["for name, p in model_last2.named_parameters():\n","    if p.requires_grad:\n","        print(\"Trainable:\", name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5212fbe4-2f17-4a9e-8443-a140b565bfca","id":"82d5jQuJPcw3","executionInfo":{"status":"ok","timestamp":1759598357201,"user_tz":240,"elapsed":58,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable: text_model.encoder.layers.10.self_attn.k_proj.weight\n","Trainable: text_model.encoder.layers.10.self_attn.k_proj.bias\n","Trainable: text_model.encoder.layers.10.self_attn.v_proj.weight\n","Trainable: text_model.encoder.layers.10.self_attn.v_proj.bias\n","Trainable: text_model.encoder.layers.10.self_attn.q_proj.weight\n","Trainable: text_model.encoder.layers.10.self_attn.q_proj.bias\n","Trainable: text_model.encoder.layers.10.self_attn.out_proj.weight\n","Trainable: text_model.encoder.layers.10.self_attn.out_proj.bias\n","Trainable: text_model.encoder.layers.10.layer_norm1.weight\n","Trainable: text_model.encoder.layers.10.layer_norm1.bias\n","Trainable: text_model.encoder.layers.10.mlp.fc1.weight\n","Trainable: text_model.encoder.layers.10.mlp.fc1.bias\n","Trainable: text_model.encoder.layers.10.mlp.fc2.weight\n","Trainable: text_model.encoder.layers.10.mlp.fc2.bias\n","Trainable: text_model.encoder.layers.10.layer_norm2.weight\n","Trainable: text_model.encoder.layers.10.layer_norm2.bias\n","Trainable: text_model.encoder.layers.11.self_attn.k_proj.weight\n","Trainable: text_model.encoder.layers.11.self_attn.k_proj.bias\n","Trainable: text_model.encoder.layers.11.self_attn.v_proj.weight\n","Trainable: text_model.encoder.layers.11.self_attn.v_proj.bias\n","Trainable: text_model.encoder.layers.11.self_attn.q_proj.weight\n","Trainable: text_model.encoder.layers.11.self_attn.q_proj.bias\n","Trainable: text_model.encoder.layers.11.self_attn.out_proj.weight\n","Trainable: text_model.encoder.layers.11.self_attn.out_proj.bias\n","Trainable: text_model.encoder.layers.11.layer_norm1.weight\n","Trainable: text_model.encoder.layers.11.layer_norm1.bias\n","Trainable: text_model.encoder.layers.11.mlp.fc1.weight\n","Trainable: text_model.encoder.layers.11.mlp.fc1.bias\n","Trainable: text_model.encoder.layers.11.mlp.fc2.weight\n","Trainable: text_model.encoder.layers.11.mlp.fc2.bias\n","Trainable: text_model.encoder.layers.11.layer_norm2.weight\n","Trainable: text_model.encoder.layers.11.layer_norm2.bias\n"]}]},{"cell_type":"markdown","source":["# 3.Parameter-Efficient Fine-Tuning (PFET)\n","\n","Instead of updating several parameters, PEFT methods adapt only a small set of additional parameters while keeping the pretrained model's backbone frozen. Popular strategies include *Adapters*, which insert lightweight bottleneck layers inside Transformer blocks, and LoRA (Low-Rank Adaptation), which learns low-rank updates to attention weights. These approaches reduce memory and computation cost while still allowing effective adaptation."],"metadata":{"id":"lUYTaNB-wAoX"}},{"cell_type":"markdown","source":["## 3.1 LoRA"],"metadata":{"id":"kcWjK9LYwSUX"}},{"cell_type":"markdown","source":["#### Apply LoRA to last N layers"],"metadata":{"id":"HbtTMgxyny1Q"}},{"cell_type":"markdown","source":["LoRA (Low-Rank Adaptation) is a parameter-efficient fine-tuning method. Instead of updating the full weight matrix, LoRA works by inserting small trainable low-rank matrices (decomposition of original weight matrix). In transformers, LoRA is inserted into attention projection matrices (usually the **query** *q_proj* and **value** *v_proj*). These are the matrices that transform hidden states into attention representations. Let's inject LoRA into the last 2 layers, while freezing the full model!"],"metadata":{"id":"uGn6CQimoCwk"}},{"cell_type":"code","source":["# load model\n","model_lora = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","# freeze all\n","for param in model_lora.parameters():\n","    param.requires_grad = False\n","\n","# list module names to tell LoRA where to insert adapters\n","target_modules = [\n","    \"text_model.encoder.layers.10.self_attn.q_proj\",\n","    \"text_model.encoder.layers.10.self_attn.v_proj\",\n","    \"text_model.encoder.layers.11.self_attn.q_proj\",\n","    \"text_model.encoder.layers.11.self_attn.v_proj\",\n","]\n","\n","# Check target modules\n","print(\"\\n\".join(target_modules))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMwCzqRGgsLt","outputId":"63707137-0a3c-4618-b9cc-12f9d4aa82bc","executionInfo":{"status":"ok","timestamp":1759598442554,"user_tz":240,"elapsed":628,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["text_model.encoder.layers.10.self_attn.q_proj\n","text_model.encoder.layers.10.self_attn.v_proj\n","text_model.encoder.layers.11.self_attn.q_proj\n","text_model.encoder.layers.11.self_attn.v_proj\n"]}]},{"cell_type":"markdown","source":["#### LoRA Configuration and Integration"],"metadata":{"id":"PwWChEiXpP32"}},{"cell_type":"markdown","source":["Choose *task_type* to be FEATURE_EXTRACTION. Other types include MULTIPLE_CHOICE for multiple-choice QA, QUESTION_ANS for question answering and others."],"metadata":{"id":"JLRPIYKfDs9u"}},{"cell_type":"code","source":["lora_config = LoraConfig(\n","    r=8, # size of LoRA rank matrices (control capacity)\n","    lora_alpha=16, # Scaling factor for the LoRA updates (8 -> 16 = 2x)\n","    target_modules=target_modules,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"FEATURE_EXTRACTION\",\n",")"],"metadata":{"id":"vA-CywoSot2r","executionInfo":{"status":"ok","timestamp":1759598556385,"user_tz":240,"elapsed":11,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# inject LoRA\n","model_lora = get_peft_model(model_lora, lora_config)\n","\n","print(\"LoRA applied\")\n","count_parameters(model_lora)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MkxL67MvDorv","outputId":"46f95cd3-283d-41e6-d80f-deec7f80754e","executionInfo":{"status":"ok","timestamp":1759598592596,"user_tz":240,"elapsed":37,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["LoRA applied\n","Trainable params: 32,768\n","Frozen params:    151,277,313\n","Total params:     151,310,081\n","Trainable ratio:  0.02%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:79: UserWarning: The PEFT config's `base_model_name_or_path` was renamed from 'openai/clip-vit-base-patch32' to 'None'. Please ensure that the correct base model is loaded when loading this checkpoint.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["#### Check trainable parameters"],"metadata":{"id":"c8lra81xQA5e"}},{"cell_type":"code","source":["for name, p in model_lora.named_parameters():\n","    if p.requires_grad:\n","        print(\"Trainable:\", name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9b54b756-eb62-438b-b068-ccb736f2b5cd","id":"FTvhRYF6QA5h","executionInfo":{"status":"ok","timestamp":1759598604429,"user_tz":240,"elapsed":14,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight\n","Trainable: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight\n","Trainable: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight\n","Trainable: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight\n","Trainable: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight\n","Trainable: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight\n","Trainable: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight\n","Trainable: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight\n"]}]},{"cell_type":"markdown","source":["#### Compare number of trainable parameters between frozen, partial freezing and LoRA"],"metadata":{"id":"WIiaZvT_vdhM"}},{"cell_type":"code","source":["def get_param_stats(model):\n","    trainable, frozen = 0, 0\n","    for _, param in model.named_parameters():\n","        if param.requires_grad:\n","            trainable += param.numel()\n","        else:\n","            frozen += param.numel()\n","    total = trainable + frozen\n","    ratio = 100 * trainable / total\n","    return trainable, frozen, total, ratio\n","\n","# Build comparison table\n","results = {\n","    \"Frozen\": get_param_stats(model),\n","    \"Projection unfrozen\": get_param_stats(model_proj),\n","    \"Last 2 layers unfrozen\": get_param_stats(model_last2),\n","    \"LoRA applied\": get_param_stats(model_lora),\n","}\n","\n","df = pd.DataFrame(results, index=[\"Trainable\", \"Frozen\", \"Total\", \"Ratio (%)\"]).T\n","\n","df[[\"Trainable\", \"Frozen\", \"Total\"]] = df[[\"Trainable\", \"Frozen\", \"Total\"]].astype(int)\n","df[\"Ratio (%)\"] = df[\"Ratio (%)\"].round(2)\n","\n","print(\"\\nComparison Table:\")\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mht323hPqNWL","outputId":"28003f37-7444-4e53-b4c5-6fc752e94a59","executionInfo":{"status":"ok","timestamp":1759598616296,"user_tz":240,"elapsed":46,"user":{"displayName":"Ahmed Safwat Abouhashem","userId":"08246025688702959686"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Comparison Table:\n","                        Trainable     Frozen      Total  Ratio (%)\n","Frozen                          0  151277313  151277313       0.00\n","Projection unfrozen        262144  151015169  151277313       0.17\n","Last 2 layers unfrozen    6304768  144972545  151277313       4.17\n","LoRA applied                32768  151277313  151310081       0.02\n"]}]},{"cell_type":"markdown","source":["#### At this point, we can flexibly freeze or unfreeze CLIP's hidden layers and projection head, and plug in Adapters or LoRA for efficient fine-tuning. Now you are ready to experiment with these strategies in your EEG-to-text captioning setup!"],"metadata":{"id":"FHXdTT85Mf22"}}]}